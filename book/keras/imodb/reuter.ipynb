{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 17s 8us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma/.bin/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/ma/.bin/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "            reuters.load_data(num_words=10000)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 4s 8us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = \\\n",
    "    dict([(value, key) for (key, value) in word_index.items()])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "reverse_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_newswire = ' ', ' '.join([reverse_word_index.get(i -3, '?') for i in test_data[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' ',\n",
       " '? the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to ? growth and expansion plans for ? inc and ? inc over the next two years a and p said the acquisition of ? in august 1986 and ? in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt ? ? of west germany reuter 3')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_newswire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, seq in enumerate(sequences):\n",
    "        results[i,seq] = 1\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1\n",
    "\n",
    "    return results\n",
    "\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 2.6752 - accuracy: 0.5249 - val_loss: 1.7489 - val_accuracy: 0.6460\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4105 - accuracy: 0.7083 - val_loss: 1.3018 - val_accuracy: 0.7040\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.0485 - accuracy: 0.7685 - val_loss: 1.1445 - val_accuracy: 0.7550\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8316 - accuracy: 0.8213 - val_loss: 1.0467 - val_accuracy: 0.7930\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6672 - accuracy: 0.8586 - val_loss: 0.9757 - val_accuracy: 0.7950\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.5348 - accuracy: 0.8913 - val_loss: 0.9586 - val_accuracy: 0.8040\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.4358 - accuracy: 0.9097 - val_loss: 0.9041 - val_accuracy: 0.8130\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.3458 - accuracy: 0.9285 - val_loss: 0.8928 - val_accuracy: 0.8130\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2896 - accuracy: 0.9364 - val_loss: 0.8781 - val_accuracy: 0.8220\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.2416 - accuracy: 0.9453 - val_loss: 0.9236 - val_accuracy: 0.8120\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2106 - accuracy: 0.9484 - val_loss: 0.9200 - val_accuracy: 0.8190\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.1834 - accuracy: 0.9533 - val_loss: 0.9347 - val_accuracy: 0.8100\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.1655 - accuracy: 0.9539 - val_loss: 0.9843 - val_accuracy: 0.8100\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1484 - accuracy: 0.9559 - val_loss: 0.9780 - val_accuracy: 0.8110\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.1427 - accuracy: 0.9553 - val_loss: 0.9952 - val_accuracy: 0.8140\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.1322 - accuracy: 0.9559 - val_loss: 1.0194 - val_accuracy: 0.8080\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.1272 - accuracy: 0.9555 - val_loss: 1.0361 - val_accuracy: 0.8120\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1220 - accuracy: 0.9569 - val_loss: 1.0246 - val_accuracy: 0.8160\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1200 - accuracy: 0.9572 - val_loss: 1.0645 - val_accuracy: 0.8030\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.1066 - accuracy: 0.9593 - val_loss: 1.0911 - val_accuracy: 0.8180\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    batch_size=512, epochs=20, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [2.6752207279205322,\n",
       "  1.4104574918746948,\n",
       "  1.048532247543335,\n",
       "  0.8316002488136292,\n",
       "  0.6672399640083313,\n",
       "  0.5348379015922546,\n",
       "  0.4358136057853699,\n",
       "  0.3457615077495575,\n",
       "  0.28959283232688904,\n",
       "  0.24163661897182465,\n",
       "  0.21062065660953522,\n",
       "  0.18337580561637878,\n",
       "  0.1655293107032776,\n",
       "  0.14839482307434082,\n",
       "  0.1426907628774643,\n",
       "  0.13223353028297424,\n",
       "  0.12724700570106506,\n",
       "  0.12196090817451477,\n",
       "  0.11999538540840149,\n",
       "  0.10664878785610199],\n",
       " 'accuracy': [0.5249310731887817,\n",
       "  0.7083437442779541,\n",
       "  0.76847904920578,\n",
       "  0.8213480114936829,\n",
       "  0.8585567474365234,\n",
       "  0.8912553191184998,\n",
       "  0.9096717834472656,\n",
       "  0.9284640550613403,\n",
       "  0.936356782913208,\n",
       "  0.9452518224716187,\n",
       "  0.9483838677406311,\n",
       "  0.9532698392868042,\n",
       "  0.9538962841033936,\n",
       "  0.9559007883071899,\n",
       "  0.9552743434906006,\n",
       "  0.9559007883071899,\n",
       "  0.9555249214172363,\n",
       "  0.9569030404090881,\n",
       "  0.9571536183357239,\n",
       "  0.9592834115028381],\n",
       " 'val_loss': [1.7488564252853394,\n",
       "  1.3018290996551514,\n",
       "  1.1445037126541138,\n",
       "  1.0466564893722534,\n",
       "  0.9756638407707214,\n",
       "  0.9586498737335205,\n",
       "  0.9041284322738647,\n",
       "  0.892783522605896,\n",
       "  0.87808758020401,\n",
       "  0.923552393913269,\n",
       "  0.9199769496917725,\n",
       "  0.9347374439239502,\n",
       "  0.9843171834945679,\n",
       "  0.9780312776565552,\n",
       "  0.9951971769332886,\n",
       "  1.0193769931793213,\n",
       "  1.0360971689224243,\n",
       "  1.0245898962020874,\n",
       "  1.0644609928131104,\n",
       "  1.0911365747451782],\n",
       " 'val_accuracy': [0.6460000276565552,\n",
       "  0.7039999961853027,\n",
       "  0.7549999952316284,\n",
       "  0.7929999828338623,\n",
       "  0.7950000166893005,\n",
       "  0.8040000200271606,\n",
       "  0.8130000233650208,\n",
       "  0.8130000233650208,\n",
       "  0.8220000267028809,\n",
       "  0.8119999766349792,\n",
       "  0.8190000057220459,\n",
       "  0.8100000023841858,\n",
       "  0.8100000023841858,\n",
       "  0.8109999895095825,\n",
       "  0.8140000104904175,\n",
       "  0.8080000281333923,\n",
       "  0.8119999766349792,\n",
       "  0.8159999847412109,\n",
       "  0.8029999732971191,\n",
       "  0.8180000185966492]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
